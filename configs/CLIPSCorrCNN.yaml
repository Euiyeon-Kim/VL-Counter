seed: 806

model: CLIPSCorrCNNv1

# Backbone - CLIP arch
clip_path: pretrained/ViT-B-16.pt
# CLIP Text
txt_emb_dim: 512
# CLIP Vision
input_resolution: 512
patch_size: 16
img_emb_dim: 768
drop_path_rate: 0.1

# Train
total_epochs: 500
batch_size: 8
num_workers: 8
valid_freq_epoch: 1
test_freq_epoch: 5

# Backbone - train
fix_txt_encoder: True
fix_img_encoder: True

# Data
use_cutmix: True
density_scale: 60
data_name: FSC147
data_root: datasets/FSC147_384_V2
img_norm_mean:
  - 0.48145466
  - 0.4578275
  - 0.40821073
img_norm_var:
  - 0.26862954
  - 0.26130258
  - 0.27577711

# Optimizer
weight_decay: 1.0e-4
backbone_lr: 1.0e-6
start_lr: 1.0e-5
end_lr: 2.0e-5
warm_up_iter: 1000
last_lr_decay_iter: 20000

# Logging
img_summary_freq: 100
metric_summary_freq: 50
save_latest_freq: 500
save_every_freq_epoch: 25
